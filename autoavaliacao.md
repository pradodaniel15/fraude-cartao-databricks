# ‚úçÔ∏è Autoavalia√ß√£o

## ‚úÖ Atingimento dos Objetivos

O trabalho cumpriu os objetivos propostos inicialmente, com a constru√ß√£o de um pipeline funcional na plataforma Databricks, envolvendo as etapas de:

- Coleta e carregamento dos dados no ambiente em nuvem;
- An√°lise da qualidade dos dados;
- Modelagem explorat√≥ria com visualiza√ß√µes;
- Respostas √†s perguntas de neg√≥cio.

As perguntas tra√ßadas no in√≠cio foram abordadas com base em an√°lises t√©cnicas, estat√≠sticas e gr√°ficas. Houve um bom entendimento do comportamento das fraudes no dataset, especialmente em rela√ß√£o ao valor das transa√ß√µes e ao hor√°rio de ocorr√™ncia.

## ‚ö†Ô∏è Dificuldades Encontradas

- O primeiro desafio foi encontrar um dataset aplic√°vel e de qualidade.
- Houve erros na aplica√ß√£o de fun√ß√µes PySpark, principalmente na an√°lise de nulos e tipos de dados.
- Ajustar visualiza√ß√µes no ambiente Databricks tamb√©m exigiu aten√ß√£o especial.

Esses obst√°culos, no entanto, contribu√≠ram para o aprendizado pr√°tico e aprofundamento no uso da plataforma.

## üöÄ Pr√≥ximos Passos

- Realizar um balanceamento do dataset com t√©cnicas como undersampling ou SMOTE.
- Aplicar modelos de machine learning para detec√ß√£o autom√°tica de fraudes.
- Expandir o pipeline com orquestra√ß√£o de tarefas (ex: Apache Airflow).
- Armazenar os dados em um Data Lake estruturado no formato Delta.

## üß† Conclus√£o

A execu√ß√£o do projeto permitiu desenvolver habilidades essenciais em engenharia de dados na nuvem. O uso do Databricks proporcionou uma boa experi√™ncia de integra√ß√£o entre an√°lise e visualiza√ß√£o. O trabalho serviu como um MVP vi√°vel e aplic√°vel em casos reais de detec√ß√£o de fraudes.